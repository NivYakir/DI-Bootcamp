{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "executionInfo": {
     "elapsed": 1963,
     "status": "ok",
     "timestamp": 1757001695467,
     "user": {
      "displayName": "Niv Yakir",
      "userId": "15988728913292912490"
     },
     "user_tz": -180
    },
    "id": "qLcvjns1hc_0",
    "outputId": "a4346fac-e6b5-47f4-fc33-6ab633a8a80b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/brendan45774/test-file\n",
      "License(s): CC0-1.0\n",
      "Downloading test-file.zip to ./data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/11.2k [00:00<?, ?B/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11.2k/11.2k [00:00<00:00, 3.01MB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>897</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Svensson, Mr. Johan Cervin</td>\n",
       "      <td>male</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7538</td>\n",
       "      <td>9.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0          892         0       3   \n",
       "1          893         1       3   \n",
       "2          894         0       2   \n",
       "3          895         0       3   \n",
       "4          896         1       3   \n",
       "5          897         0       3   \n",
       "\n",
       "                                           Name     Sex   Age  SibSp  Parch  \\\n",
       "0                              Kelly, Mr. James    male  34.5      0      0   \n",
       "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
       "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
       "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
       "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
       "5                    Svensson, Mr. Johan Cervin    male  14.0      0      0   \n",
       "\n",
       "    Ticket     Fare Cabin Embarked  \n",
       "0   330911   7.8292   NaN        Q  \n",
       "1   363272   7.0000   NaN        S  \n",
       "2   240276   9.6875   NaN        Q  \n",
       "3   315154   8.6625   NaN        S  \n",
       "4  3101298  12.2875   NaN        S  \n",
       "5     7538   9.2250   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data manipulation and analysis\n",
    "import matplotlib.pyplot as plt # data visualization\n",
    "import seaborn as sns # data visualization\n",
    "sns.set_style('whitegrid') # set style for visualization\n",
    "import warnings # ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "!kaggle datasets download -d brendan45774/test-file -p ./data --unzip\n",
    "titanic_data = pd.read_csv('./data/tested.csv')\n",
    "titanic_data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1757002453624,
     "user": {
      "displayName": "Niv Yakir",
      "userId": "15988728913292912490"
     },
     "user_tz": -180
    },
    "id": "1RSc1GM775gb",
    "outputId": "47a3c79e-4f87-4b29-8c60-06caf880918a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Survived     418 non-null    int64  \n",
      " 2   Pclass       418 non-null    int64  \n",
      " 3   Name         418 non-null    object \n",
      " 4   Sex          418 non-null    object \n",
      " 5   Age          332 non-null    float64\n",
      " 6   SibSp        418 non-null    int64  \n",
      " 7   Parch        418 non-null    int64  \n",
      " 8   Ticket       418 non-null    object \n",
      " 9   Fare         417 non-null    float64\n",
      " 10  Cabin        91 non-null     object \n",
      " 11  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 39.3+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "executionInfo": {
     "elapsed": 144,
     "status": "ok",
     "timestamp": 1757002447457,
     "user": {
      "displayName": "Niv Yakir",
      "userId": "15988728913292912490"
     },
     "user_tz": -180
    },
    "id": "aNS71ZDp8Bt2",
    "outputId": "c46d37c0-facc-4b4c-e5e8-e1e0503bfee8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>2.265550</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.481622</td>\n",
       "      <td>0.841838</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   418.000000  418.000000  418.000000  332.000000  418.000000   \n",
       "mean   1100.500000    0.363636    2.265550   30.272590    0.447368   \n",
       "std     120.810458    0.481622    0.841838   14.181209    0.896760   \n",
       "min     892.000000    0.000000    1.000000    0.170000    0.000000   \n",
       "25%     996.250000    0.000000    1.000000   21.000000    0.000000   \n",
       "50%    1100.500000    0.000000    3.000000   27.000000    0.000000   \n",
       "75%    1204.750000    1.000000    3.000000   39.000000    1.000000   \n",
       "max    1309.000000    1.000000    3.000000   76.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  418.000000  417.000000  \n",
       "mean     0.392344   35.627188  \n",
       "std      0.981429   55.907576  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.895800  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.500000  \n",
       "max      9.000000  512.329200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cOME1wbm78Fs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.272590361445783\n"
     ]
    }
   ],
   "source": [
    "age_mean_men = titanic_data['Age'].mean()\n",
    "print(age_mean_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 95,
     "status": "ok",
     "timestamp": 1757000728231,
     "user": {
      "displayName": "Niv Yakir",
      "userId": "15988728913292912490"
     },
     "user_tz": -180
    },
    "id": "0XrkCurlhdDH",
    "outputId": "2b718a33-8c52-422f-aaf9-1294410b75e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Has_Pets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Has_Pets\n",
       "0          892      True\n",
       "1          893      True\n",
       "2          894     False\n",
       "3          895     False\n",
       "4          896     False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate extra demographic data (for integration example)\n",
    "demographics = titanic_data[['PassengerId']].copy()\n",
    "# Create a new column in the demographics pd, column='Has_Pets' and is randomly assigned either True or False\n",
    "demographics['Has_Pets'] = np.random.choice([True, False], size=len(demographics))\n",
    "# print(demographics)\n",
    "\n",
    "# Merge\n",
    "titanic_data = pd.merge(titanic_data, demographics, on='PassengerId', how='left')  # Notice when merging 2 dataframes, the column name has to be exactly the same\n",
    "titanic_data[['PassengerId', 'Has_Pets']].head()\n",
    "\n",
    "# The LEFT JOIN keyword returns all records from the left table (table1), and the matching records from the right table (table2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1757002494052,
     "user": {
      "displayName": "Niv Yakir",
      "userId": "15988728913292912490"
     },
     "user_tz": -180
    },
    "id": "TrUrQ4ISb2GZ",
    "outputId": "61a0f7cb-f7a6-4cc5-f5dc-57d50602fe47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "413    False\n",
      "414    False\n",
      "415    False\n",
      "416    False\n",
      "417    False\n",
      "Length: 418, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "duplicate_mask = titanic_data.duplicated()\n",
    "print(duplicate_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1757001290716,
     "user": {
      "displayName": "Niv Yakir",
      "userId": "15988728913292912490"
     },
     "user_tz": -180
    },
    "id": "KxtUXAOHlYWK",
    "outputId": "ce338a27-fdc3-493c-96fd-7a3b25087adc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 1\n",
      "     PassengerId  Survived  Pclass              Name   Sex   Age  SibSp  \\\n",
      "418          892         0       3  Kelly, Mr. James  male  34.5      0   \n",
      "\n",
      "     Parch  Ticket    Fare Cabin Embarked  Has_Pets  \n",
      "418      0  330911  7.8292   NaN        Q      True  \n"
     ]
    }
   ],
   "source": [
    "## 2.Add a duplicate of the first row\n",
    "titanic_data = pd.concat([titanic_data, titanic_data.iloc[[0]]], ignore_index=True)\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_mask = titanic_data.duplicated()\n",
    "\n",
    "# Print number of duplicate rows\n",
    "print(\"Number of duplicate rows:\", duplicate_mask.sum())\n",
    "\n",
    "# Optionally, view the duplicated rows\n",
    "print(titanic_data[duplicate_mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1757001343538,
     "user": {
      "displayName": "Niv Yakir",
      "userId": "15988728913292912490"
     },
     "user_tz": -180
    },
    "id": "swzPFshfBn-L",
    "outputId": "ba1eed66-afa5-4bcf-9661-b0dddd9ae77f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# Remove Duplicates\n",
    "titanic_data = titanic_data.drop_duplicates()\n",
    "print(\"Remaining duplicates:\", titanic_data.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1757002508154,
     "user": {
      "displayName": "Niv Yakir",
      "userId": "15988728913292912490"
     },
     "user_tz": -180
    },
    "id": "sGmji09oB4J1",
    "outputId": "82f6e7d1-5c03-4c89-9cee-0df248d30194"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after removal: Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Fare', 'Embarked', 'Has_Pets'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Remove Irrelevant Columns\n",
    "# It is safer to copy the original data and drop the irrelevant columns from the copy\n",
    "titanic_data = titanic_data.drop(['Cabin', 'Ticket'], axis=1, errors='ignore')\n",
    "print(\"Columns after removal:\", titanic_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1757001781380,
     "user": {
      "displayName": "Niv Yakir",
      "userId": "15988728913292912490"
     },
     "user_tz": -180
    },
    "id": "nYtjnvcUDpFE",
    "outputId": "b45a0a3e-93b3-4b6f-db01-cb02220daac4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date\n",
      "0 1912-01-01\n",
      "1 1912-01-02\n",
      "2 1912-01-03\n",
      "3 1912-01-04\n",
      "4 1912-01-05\n"
     ]
    }
   ],
   "source": [
    "# Fixing Structural Errors - simulate 'Date' column\n",
    "titanic_data['Date'] = pd.date_range(start='1/1/1912', periods=len(titanic_data), freq='D')\n",
    "titanic_data['Date'] = pd.to_datetime(titanic_data['Date'])\n",
    "print(titanic_data[['Date']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1757002531407,
     "user": {
      "displayName": "Niv Yakir",
      "userId": "15988728913292912490"
     },
     "user_tz": -180
    },
    "id": "LNYOF0S6e6G7",
    "outputId": "d2b4ed4c-50ba-4ef6-d48d-e3c192820c81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass   Name    Sex    Age  SibSp  Parch   Fare  \\\n",
      "0        False     False   False  False  False  False  False  False  False   \n",
      "1        False     False   False  False  False  False  False  False  False   \n",
      "2        False     False   False  False  False  False  False  False  False   \n",
      "3        False     False   False  False  False  False  False  False  False   \n",
      "4        False     False   False  False  False  False  False  False  False   \n",
      "\n",
      "   Embarked  Has_Pets   Date  \n",
      "0     False     False  False  \n",
      "1     False     False  False  \n",
      "2     False     False  False  \n",
      "3     False     False  False  \n",
      "4     False     False  False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Check for missing values in a DataFrame\n",
    "missing_data = titanic_data.isnull()\n",
    "print(missing_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1757003484700,
     "user": {
      "displayName": "Niv Yakir",
      "userId": "15988728913292912490"
     },
     "user_tz": -180
    },
    "id": "SDe_LCcxC2MZ",
    "outputId": "23be0d47-7c22-49fe-c107-929671661834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "PassengerId     0\n",
      "Survived        0\n",
      "Pclass          0\n",
      "Name            0\n",
      "Sex             0\n",
      "Age            86\n",
      "SibSp           0\n",
      "Parch           0\n",
      "Fare            1\n",
      "Embarked        0\n",
      "Has_Pets        0\n",
      "Date            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identify Missing\n",
    "print(\"Missing values per column:\")\n",
    "print(titanic_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1757003838247,
     "user": {
      "displayName": "Niv Yakir",
      "userId": "15988728913292912490"
     },
     "user_tz": -180
    },
    "id": "NTn-FvesnEkd",
    "outputId": "b81eb773-1a1f-440e-d3d5-afee9339966d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Fare           1\n",
      "Embarked       0\n",
      "Has_Pets       0\n",
      "Date           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of the dataset to not permanently damage the original set\n",
    "titanic_filled = titanic_data.copy()\n",
    "\n",
    "# SYNTAX : UPDATED_COLUMN = DESIRED COLUMN . fill null values (mean of the 'Age' column of titanic dataset)\n",
    "# This fills all the NULL values in the 'Age' column with the average age of the entire set\n",
    "titanic_filled['Age'] = titanic_filled['Age'].fillna(titanic_filled['Age'].mean())\n",
    "\n",
    "# Check if this worked\n",
    "print(\"Missing values per column:\")\n",
    "print(titanic_filled.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3af6bsNnE0O"
   },
   "source": [
    "KNNImputer is a technique for filling in missing values based on the values of the k-nearest neighbors (rows that are similar in other features). Itâ€™s more intelligent than filling with mean or median, because it accounts for relationships between features.\n",
    "\n",
    "âœ… Create the imputer object.\n",
    "\n",
    "n_neighbors=3 means for each missing value, the algorithm will:\n",
    "\n",
    "Find the 3 rows most similar to the one with missing data (based on other numeric columns).\n",
    "\n",
    "Use their values to compute the average and fill in the missing value.\n",
    "\n",
    "\n",
    " Filter only numeric columns, because KNNImputer can only work with numbers.\n",
    "This ensures we donâ€™t feed in strings or categories like 'Sex' or 'Embarked'.\n",
    "\n",
    "\n",
    "Perform the imputation:\n",
    "\n",
    "fit_transform() does two things:\n",
    "\n",
    "Fit: Learns how to find neighbors based on available (non-missing) data.\n",
    "\n",
    "Transform: Fills in the missing values using neighbor-based averages.\n",
    "\n",
    "The result is a NumPy array with all missing values filled.\n",
    "\n",
    "âœ… Convert the result back to a DataFrame, keeping the original column names.\n",
    "\n",
    "âœ… Just to check: Print the first few rows of the cleaned, imputed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1982,
     "status": "ok",
     "timestamp": 1757004213681,
     "user": {
      "displayName": "Niv Yakir",
      "userId": "15988728913292912490"
     },
     "user_tz": -180
    },
    "id": "ilVnS2Npiz4c",
    "outputId": "cba06cd7-1f7d-4874-94e0-2bdbd3161ebf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass   Age  SibSp  Parch     Fare\n",
      "0        892.0       0.0     3.0  34.5    0.0    0.0   7.8292\n",
      "1        893.0       1.0     3.0  47.0    1.0    0.0   7.0000\n",
      "2        894.0       0.0     2.0  62.0    0.0    0.0   9.6875\n",
      "3        895.0       0.0     3.0  27.0    0.0    0.0   8.6625\n",
      "4        896.0       1.0     3.0  22.0    1.0    1.0  12.2875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "df_numeric = titanic_data.select_dtypes(include=['float64', 'int64'])\n",
    "imputed_array = imputer.fit_transform(df_numeric)\n",
    "df_imputed = pd.DataFrame(imputed_array, columns=df_numeric.columns)\n",
    "print(df_imputed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1757005829340,
     "user": {
      "displayName": "Niv Yakir",
      "userId": "15988728913292912490"
     },
     "user_tz": -180
    },
    "id": "k8wpKHEWi4HH",
    "outputId": "9c358ce2-0596-466c-9fe3-5ae4f4fa3655"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (418, 12)\n",
      "Shape after removing fare outliers: (362, 12)\n",
      "Outliers: (55, 12)\n"
     ]
    }
   ],
   "source": [
    "# Identify and handle outliers in the 'Fare' column\n",
    "Q1 = titanic_data['Fare'].quantile(0.25)\n",
    "Q3 = titanic_data['Fare'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Determine the upper/lower bounds for outlier values\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Present only values in the Inter-Quartile-Range (IQR)\n",
    "filtered_fare = titanic_data[(titanic_data['Fare'] >= lower_bound) & (titanic_data['Fare'] <= upper_bound)]\n",
    "print(\"Original shape:\", titanic_data.shape)\n",
    "print(\"Shape after removing fare outliers:\", filtered_fare.shape)\n",
    "\n",
    "outlier_fare = titanic_data[(titanic_data['Fare'] < lower_bound) | (titanic_data['Fare'] > upper_bound)]\n",
    "print(\"Outliers:\", outlier_fare.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bam3ftdoe0O"
   },
   "source": [
    "Whatâ€™s going on?\n",
    "Q1 (25th percentile) is the value below which 25% of the data falls.\n",
    "\n",
    "Q3 (75th percentile) is the value below which 75% of the data falls.\n",
    "\n",
    "IQR (Interquartile Range) is the difference between Q3 and Q1:\n",
    "\n",
    "IQR\n",
    "=\n",
    "ð‘„\n",
    "3\n",
    "âˆ’\n",
    "ð‘„\n",
    "1\n",
    "IQR=Q3âˆ’Q1\n",
    "It measures the spread of the middle 50% of the data.\n",
    "\n",
    "\n",
    "Whatâ€™s going on?\n",
    "These formulas define the acceptable range for Age.\n",
    "\n",
    "Any value outside this range is considered an outlier.\n",
    "\n",
    "LowerÂ Bound\n",
    "=\n",
    "ð‘„\n",
    "1\n",
    "âˆ’\n",
    "1.5\n",
    "Ã—\n",
    "ð¼\n",
    "ð‘„\n",
    "ð‘…\n",
    "LowerÂ Bound=Q1âˆ’1.5Ã—IQR\n",
    "UpperÂ Bound\n",
    "=\n",
    "ð‘„\n",
    "3\n",
    "+\n",
    "1.5\n",
    "Ã—\n",
    "ð¼\n",
    "ð‘„\n",
    "ð‘…\n",
    "UpperÂ Bound=Q3+1.5Ã—IQR\n",
    "This \"1.5 * IQR\" rule is a common statistical convention:\n",
    "\n",
    "Too far below = unusually small â†’ outlier\n",
    "\n",
    "Too far above = unusually large â†’ outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1757005124951,
     "user": {
      "displayName": "Niv Yakir",
      "userId": "15988728913292912490"
     },
     "user_tz": -180
    },
    "id": "TXQhy3Uki93s",
    "outputId": "1e809b2e-e64d-47bc-8837-407f50078914"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shape: (418, 12)\n",
      "IQR Shape: (330, 12)\n",
      "Outliers: (2, 12)\n"
     ]
    }
   ],
   "source": [
    "# 1. Q1 and Q3\n",
    "Q1 = titanic_data['Age'].quantile(0.25)\n",
    "Q3 = titanic_data['Age'].quantile(0.75)\n",
    "\n",
    "# 2. Bounds\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# 3. Count Outliers\n",
    "quartile_age = titanic_data[(titanic_data['Age'] >= lower_bound) & (titanic_data['Age'] <= upper_bound)]\n",
    "print(\"Original Shape:\", titanic_data.shape)\n",
    "print(\"IQR Shape:\", quartile_age.shape)\n",
    "\n",
    "outliers = titanic_data[(titanic_data['Age'] < lower_bound) | (titanic_data['Age'] > upper_bound)]\n",
    "print(\"Outliers:\", outliers.shape)  # Doesn't give the complement of the IQR (891 - 703) due to the null values in titanic_data['Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1757005943698,
     "user": {
      "displayName": "Niv Yakir",
      "userId": "15988728913292912490"
     },
     "user_tz": -180
    },
    "id": "co8pgFUxp5DN",
    "outputId": "d0c0b95f-fc39-44eb-df68-cb2941f617b2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Purchase_Amount</th>\n",
       "      <th>Purchase_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>67194</td>\n",
       "      <td>30</td>\n",
       "      <td>352</td>\n",
       "      <td>2024-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>117498</td>\n",
       "      <td>38</td>\n",
       "      <td>847</td>\n",
       "      <td>2024-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>74131</td>\n",
       "      <td>2</td>\n",
       "      <td>956</td>\n",
       "      <td>2024-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>90263</td>\n",
       "      <td>64</td>\n",
       "      <td>660</td>\n",
       "      <td>2024-02-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>46023</td>\n",
       "      <td>60</td>\n",
       "      <td>574</td>\n",
       "      <td>2024-03-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Age  Annual_Income  Spending_Score  Purchase_Amount  \\\n",
       "0           1   56          67194              30              352   \n",
       "1           2   69         117498              38              847   \n",
       "2           3   46          74131               2              956   \n",
       "3           4   32          90263              64              660   \n",
       "4           5   60          46023              60              574   \n",
       "\n",
       "  Purchase_Date  \n",
       "0    2024-01-01  \n",
       "1    2024-01-16  \n",
       "2    2024-01-31  \n",
       "3    2024-02-15  \n",
       "4    2024-03-01  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a sample dataset\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'CustomerID': range(1, 11),\n",
    "    'Age': np.random.randint(18, 70, 10),\n",
    "    'Annual_Income': np.random.randint(30000, 120000, 10),\n",
    "    'Spending_Score': np.random.randint(1, 100, 10),\n",
    "    'Purchase_Amount': np.random.randint(100, 1000, 10),\n",
    "    'Purchase_Date': pd.date_range(start='2024-01-01', periods=10, freq='15D')\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sAmRH_dqpox"
   },
   "source": [
    "âœ… 1. Data Normalization\n",
    "What it is: Rescaling features to a standard range (typically 0 to 1) so that no feature dominates others due to its scale.\n",
    "\n",
    "Why it's important: Algorithms like KNN, clustering, and PCA are sensitive to scale â€” normalization helps them treat all features equally.\n",
    "\n",
    "In the example: We normalized Age, Annual_Income, and Spending_Score using MinMaxScaler to create new columns ending in _norm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "n_Jtpy52qAlM"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Purchase_Amount</th>\n",
       "      <th>Purchase_Date</th>\n",
       "      <th>Age_norm</th>\n",
       "      <th>Annual_Income_norm</th>\n",
       "      <th>Spending_Score_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>67194</td>\n",
       "      <td>30</td>\n",
       "      <td>352</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.419986</td>\n",
       "      <td>0.378378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>117498</td>\n",
       "      <td>38</td>\n",
       "      <td>847</td>\n",
       "      <td>2024-01-16</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.486486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>74131</td>\n",
       "      <td>2</td>\n",
       "      <td>956</td>\n",
       "      <td>2024-01-31</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.499971</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>90263</td>\n",
       "      <td>64</td>\n",
       "      <td>660</td>\n",
       "      <td>2024-02-15</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.685976</td>\n",
       "      <td>0.837838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>46023</td>\n",
       "      <td>60</td>\n",
       "      <td>574</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.175881</td>\n",
       "      <td>0.783784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>71090</td>\n",
       "      <td>21</td>\n",
       "      <td>158</td>\n",
       "      <td>2024-03-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.464908</td>\n",
       "      <td>0.256757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>97221</td>\n",
       "      <td>33</td>\n",
       "      <td>610</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.766203</td>\n",
       "      <td>0.418919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>56</td>\n",
       "      <td>94820</td>\n",
       "      <td>76</td>\n",
       "      <td>781</td>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.738519</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>36</td>\n",
       "      <td>30769</td>\n",
       "      <td>58</td>\n",
       "      <td>575</td>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>89735</td>\n",
       "      <td>22</td>\n",
       "      <td>799</td>\n",
       "      <td>2024-05-15</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.679888</td>\n",
       "      <td>0.270270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Age  Annual_Income  Spending_Score  Purchase_Amount  \\\n",
       "0           1   56          67194              30              352   \n",
       "1           2   69         117498              38              847   \n",
       "2           3   46          74131               2              956   \n",
       "3           4   32          90263              64              660   \n",
       "4           5   60          46023              60              574   \n",
       "5           6   25          71090              21              158   \n",
       "6           7   38          97221              33              610   \n",
       "7           8   56          94820              76              781   \n",
       "8           9   36          30769              58              575   \n",
       "9          10   40          89735              22              799   \n",
       "\n",
       "  Purchase_Date  Age_norm  Annual_Income_norm  Spending_Score_norm  \n",
       "0    2024-01-01  0.704545            0.419986             0.378378  \n",
       "1    2024-01-16  1.000000            1.000000             0.486486  \n",
       "2    2024-01-31  0.477273            0.499971             0.000000  \n",
       "3    2024-02-15  0.159091            0.685976             0.837838  \n",
       "4    2024-03-01  0.795455            0.175881             0.783784  \n",
       "5    2024-03-16  0.000000            0.464908             0.256757  \n",
       "6    2024-03-31  0.295455            0.766203             0.418919  \n",
       "7    2024-04-15  0.704545            0.738519             1.000000  \n",
       "8    2024-04-30  0.250000            0.000000             0.756757  \n",
       "9    2024-05-15  0.340909            0.679888             0.270270  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 1. Data Normalization (Min-Max Scaling)\n",
    "scaler = MinMaxScaler()\n",
    "df[['Age_norm', 'Annual_Income_norm', 'Spending_Score_norm']] = scaler.fit_transform(\n",
    "    df[['Age', 'Annual_Income', 'Spending_Score']]\n",
    ")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDqiTbmvqq7L"
   },
   "source": [
    "âœ… 2. Data Reduction using PCA\n",
    "What it is: Reduces the number of columns (features) while keeping most of the information.\n",
    "\n",
    "Why it's important: Makes data easier to visualize and can improve performance in high-dimensional datasets.\n",
    "\n",
    "In the example: We used PCA to reduce the normalized features to two components (PCA1, PCA2) â€” these represent the most meaningful variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1DulHz-AqLil"
   },
   "outputs": [],
   "source": [
    "# 2. Data Reduction using PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_features = pca.fit_transform(df[['Age_norm', 'Annual_Income_norm', 'Spending_Score_norm']])\n",
    "df[['PCA1', 'PCA2']] = pca_features\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_v6D4fPEsvX_"
   },
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwMMjr9NtH8o"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting PCA1 vs PCA2 with labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df['PCA1'], df['PCA2'], c='blue', edgecolors='k', s=80)\n",
    "plt.title('PCA: Data Projection onto 2 Principal Components')\n",
    "plt.xlabel('Principal Component 1 (PCA1)')\n",
    "plt.ylabel('Principal Component 2 (PCA2)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtWUL9tOrHJo"
   },
   "source": [
    "âœ… 3. Data Aggregation\n",
    "What it is: Summarizing data â€” typically grouping by a category or time period and applying aggregation functions (e.g., sum, mean).\n",
    "\n",
    "Why it's important: Allows simplification of raw data for trend analysis, reporting, or dashboard creation.\n",
    "\n",
    "In the example: We aggregated the Purchase_Amount by month using .groupby() to see how total purchases vary over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cw8LQhHFqLqX"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 3. Data Aggregation - Group by Month and calculate total Purchase_Amount\n",
    "df['Month'] = df['Purchase_Date'].dt.to_period('M')\n",
    "monthly_agg = df.groupby(['Month', 'CustomerID']).agg(\n",
    "    Purchase_Amount_min=('Purchase_Amount', 'min'),\n",
    "    Purchase_Amount_max=('Purchase_Amount', 'max')\n",
    ").reset_index()\n",
    "\n",
    "print(monthly_agg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84sJkAj7qbdY"
   },
   "source": [
    "âœ… 1. Data Normalization\n",
    "What it is: Rescaling features to a standard range (typically 0 to 1) so that no feature dominates others due to its scale.\n",
    "\n",
    "Why it's important: Algorithms like KNN, clustering, and PCA are sensitive to scale â€” normalization helps them treat all features equally.\n",
    "\n",
    "In the example: We normalized Age, Annual_Income, and Spending_Score using MinMaxScaler to create new columns ending in _norm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VXrdft5tRch0"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()\n",
    " # Upload kaggle.json# âœ… 2. Import libraries and load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "weather_data = pd.read_csv('weatherHistory.csv')\n",
    "print(weather_data.head(6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "csIv8PhmZw3l"
   },
   "outputs": [],
   "source": [
    "print(weather_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQ09CCEmZxnk"
   },
   "outputs": [],
   "source": [
    "print(weather_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynPQQ4RPZ1yE"
   },
   "outputs": [],
   "source": [
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Z9oIjktZ42S"
   },
   "outputs": [],
   "source": [
    "# 1. Data Normalization (Min-Max Scaling)\n",
    "scaler = MinMaxScaler()\n",
    "weather_data[['Temperature (C)_norm', 'Wind Speed (km/h)_norm', 'Pressure (millibars)_norm']] = scaler.fit_transform(\n",
    "    weather_data[['Temperature (C)', 'Wind Speed (km/h)', 'Pressure (millibars)']]\n",
    ")\n",
    "weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MVpxbz3uZ8_9"
   },
   "outputs": [],
   "source": [
    "# 2. Data Reduction using PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_features = pca.fit_transform(weather_data[['Temperature (C)_norm', 'Wind Speed (km/h)_norm', 'Pressure (millibars)_norm']])\n",
    "weather_data[['PCA1', 'PCA2']] = pca_features\n",
    "weather_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R080Lef4aBHB"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plotting PCA1 vs PCA2 with labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(weather_data['PCA1'], weather_data['PCA2'], c='blue', edgecolors='k', s=80)\n",
    "plt.title('PCA: Data Projection onto 2 Principal Components')\n",
    "plt.xlabel('Principal Component 1 (PCA1)')\n",
    "plt.ylabel('Principal Component 2 (PCA2)')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Odq3prI-aHKL"
   },
   "outputs": [],
   "source": [
    " # 3. Data Aggregation - Group by Month and calculate the average Temperature (C)\n",
    "weather_data['Formatted Date'] = pd.to_datetime(weather_data['Formatted Date'], utc=True)\n",
    "weather_data['Month'] = weather_data['Formatted Date'].dt.to_period('M')\n",
    "\n",
    "daily_agg = weather_data.groupby('Month').agg({'Temperature (C)': 'mean'})\n",
    "daily_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubOkXigWStTz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# 1. Data Normalization\n",
    "scaler = MinMaxScaler()\n",
    "numerical_cols = weather_data.select_dtypes(include='number').columns\n",
    "weather_data_normalized = scaler.fit_transform(weather_data[numerical_cols])\n",
    "weather_data[[col + '_norm' for col in numerical_cols]] = pd.DataFrame(weather_data_normalized, columns=[col + '_norm' for col in numerical_cols])\n",
    "weather_data\n",
    "\n",
    "# 2. PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(weather_data[[col + '_norm' for col in numerical_cols]])\n",
    "weather_data[['PCA1', 'PCA2']] = pca_result\n",
    "\n",
    "# 3. Aggregation: Average temperature and humidity by summary\n",
    "weather_agg = weather_data.groupby('Daily Summary').agg(\n",
    "    Avg_Temp=('Apparent Temperature (C)', 'mean'),\n",
    "    Avg_Humidity=('Humidity', 'mean')\n",
    ").reset_index()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
