import numpy as np
import matplotlib.pyplot as plt
import statsmodels
from statsmodels.stats.power import zt_ind_solve_power
from statsmodels.stats.proportion import proportion_effectsize

# ==========================================
# TASK 1: Calculate Required Sample Size
# ==========================================
print("=" * 60)
print("TASK 1: Sample Size Calculation for Bakery A/B Test")
print("=" * 60)

# Given parameters
current_conversion = 0.05  # 5% current conversion rate
new_conversion = 0.07      # 7% expected new conversion rate
alpha = 0.05               # Significance level
power = 0.8                # Desired power (1 - beta)
effect_size_given = 0.2    # Given effect size

# Calculate Cohen's h effect size for proportions
effect_size_calculated = proportion_effectsize(new_conversion, current_conversion)

print(f"\nGiven Information:")
print(f"  Current conversion rate: {current_conversion*100}%")
print(f"  New conversion rate: {new_conversion*100}%")
print(f"  Significance level (Œ±): {alpha}")
print(f"  Desired power: {power}")
print(f"  Given effect size: {effect_size_given}")
print(f"  Calculated Cohen's h: {effect_size_calculated:.4f}")

# Calculate sample size per group using the GIVEN effect size
sample_size_per_group = zt_ind_solve_power(
    effect_size=effect_size_given,
    alpha=alpha,
    power=power,
    ratio=1.0,  # Equal sample sizes in both groups
    alternative='two-sided'
)

print(f"\nüìä RESULTS:")
print(f"  Sample size per group: {int(np.ceil(sample_size_per_group))}")
print(f"  Total sample size needed: {int(np.ceil(sample_size_per_group)) * 2}")

# ==========================================
# TASK 2: Analyze Impact of Different Effect Sizes
# ==========================================
print("\n" + "=" * 60)
print("TASK 2: Impact of Different Effect Sizes")
print("=" * 60)

effect_sizes = [0.1, 0.2, 0.3, 0.4]
sample_sizes = []

print("\nSample Size Requirements for Different Effect Sizes:")
print("-" * 60)

for es in effect_sizes:
    n = zt_ind_solve_power(
        effect_size=es,
        alpha=alpha,
        power=power,
        ratio=1.0,
        alternative='two-sided'
    )
    sample_sizes.append(int(np.ceil(n)))
    print(f"  Effect Size: {es:.1f} ‚Üí Sample per group: {int(np.ceil(n)):,} ‚Üí Total: {int(np.ceil(n))*2:,}")

# ==========================================
# TASK 3: Visualization
# ==========================================
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# Plot 1: Sample Size vs Effect Size
ax1.plot(effect_sizes, sample_sizes, 'bo-', linewidth=2, markersize=10)
ax1.set_xlabel('Effect Size (Cohen\'s h)', fontsize=12, fontweight='bold')
ax1.set_ylabel('Sample Size per Group', fontsize=12, fontweight='bold')
ax1.set_title('Sample Size Requirements vs Effect Size\n(Œ±=0.05, power=0.8)', 
              fontsize=13, fontweight='bold')
ax1.grid(True, alpha=0.3)
ax1.set_ylim(0, max(sample_sizes) * 1.1)

# Add value labels on points
for es, ss in zip(effect_sizes, sample_sizes):
    ax1.annotate(f'{ss:,}', xy=(es, ss), xytext=(0, 10),
                textcoords='offset points', ha='center', fontweight='bold')

# Plot 2: Inverse Relationship (Hyperbolic curve)
ax2.plot(effect_sizes, sample_sizes, 'ro-', linewidth=2, markersize=10)
ax2.set_xlabel('Effect Size', fontsize=12, fontweight='bold')
ax2.set_ylabel('Sample Size per Group', fontsize=12, fontweight='bold')
ax2.set_title('The Inverse Relationship:\nSmaller Effect = More Samples Needed', 
              fontsize=13, fontweight='bold')
ax2.grid(True, alpha=0.3)
ax2.set_yscale('log')  # Log scale shows the relationship more clearly

# Add annotations
ax2.annotate('Small effects need\nLOTS of samples!', 
            xy=(0.1, sample_sizes[0]), xytext=(0.15, sample_sizes[0]*2),
            arrowprops=dict(arrowstyle='->', color='red', lw=2),
            fontsize=10, color='red', fontweight='bold')

ax2.annotate('Large effects need\nfewer samples', 
            xy=(0.4, sample_sizes[3]), xytext=(0.35, sample_sizes[3]/2),
            arrowprops=dict(arrowstyle='->', color='green', lw=2),
            fontsize=10, color='green', fontweight='bold')

plt.tight_layout()
plt.savefig('sample_size_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# ==========================================
# TASK 3: Explanation
# ==========================================
print("\n" + "=" * 60)
print("TASK 3: Understanding the Relationship")
print("=" * 60)

print("""
ü•ê THE BAKERY'S GUIDE TO A/B TESTING ü•ê

Imagine you're tasting pastries to find the best recipe:

1Ô∏è‚É£  WHAT IS EFFECT SIZE?
   Effect size is like the DIFFERENCE in deliciousness between two recipes.
   
   - SMALL effect (0.1): "Hmm, this croissant is slightly flakier"
   - LARGE effect (0.4): "WOW! This croissant is DRAMATICALLY better!"

2Ô∏è‚É£  WHY DOES SAMPLE SIZE CHANGE?
   
   The SMALLER the difference, the MORE taste tests you need to be sure!
   
   üìä Our Results Show:
   ‚Ä¢ Effect 0.1 ‚Üí Need {:,} customers per group (tiny improvement, need lots of data!)
   ‚Ä¢ Effect 0.2 ‚Üí Need {:,} customers per group
   ‚Ä¢ Effect 0.3 ‚Üí Need {:,} customers per group  
   ‚Ä¢ Effect 0.4 ‚Üí Need {:,} customers per group (big improvement, fewer tests needed!)

3Ô∏è‚É£  THE INVERSE RELATIONSHIP:
   
   Sample Size ‚âà 1 / (Effect Size)¬≤
   
   When effect size DOUBLES (0.2 ‚Üí 0.4):
   Sample size drops to about 1/4 (from {:,} to {:,})!
   
   Think of it like this:
   - Spotting a GIANT cake (large effect) ‚Üí Easy! Don't need many looks
   - Spotting a tiny sprinkle difference (small effect) ‚Üí Hard! Need many looks

4Ô∏è‚É£  WHY THIS MATTERS FOR YOUR BAKERY:
   
   ‚è∞ TIME: Detecting small improvements takes WEEKS of data collection
   üí∞ COST: More samples = more resources spent on testing
   üéØ CONFIDENCE: Proper sample size ensures you're not fooled by random luck
   
   Real example from YOUR test:
   - Going from 5% ‚Üí 7% conversion (effect ~0.04-0.05 in reality)
   - Using effect size 0.2 needs {:,} customers per group
   - That's {:,} total customers!
   - At 100 visitors/day = about {:,} days per group

5Ô∏è‚É£  THE GOLDEN BALANCE:
   
   ‚úÖ TOO SMALL sample ‚Üí Might miss real improvements (lose money!)
   ‚úÖ TOO LARGE sample ‚Üí Waste time testing when you could be selling!
   ‚úÖ JUST RIGHT ‚Üí Confidently detect real improvements efficiently!

üéØ BOTTOM LINE FOR THE BAKERY TEAM:
   "Bigger differences are easier to spot with fewer customers.
    Tiny improvements need lots of data to confirm they're real.
    Plan your sample size BEFORE testing to avoid wasted effort!"
""".format(sample_sizes[0], sample_sizes[1], sample_sizes[2], sample_sizes[3],
           sample_sizes[1], sample_sizes[3],
           sample_sizes[1], sample_sizes[1]*2, 
           int(np.ceil(sample_sizes[1]/100))))

print("\n" + "=" * 60)
print("üìà Key Takeaway:")
print("=" * 60)
print("""
As effect size INCREASES ‚Üí Sample size DECREASES (inverse relationship)

Why? Statistics works like detective work:
- BIG clues (large effects) ‚Üí Easy to spot ‚Üí Need less evidence
- SMALL clues (small effects) ‚Üí Hard to spot ‚Üí Need more evidence

This is why balancing effect size and sample size is crucial for:
‚úì Efficient resource allocation
‚úì Timely decision-making
‚úì Statistical confidence
‚úì Avoiding false positives or false negatives
""")